{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb94d17",
   "metadata": {},
   "source": [
    "As usual we're start with cleaning and attempt to delay EDA until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28c57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75d5f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>education_level</th>\n",
       "      <th>occupation</th>\n",
       "      <th>health_score</th>\n",
       "      <th>location</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_claims</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>insurance_duration</th>\n",
       "      <th>policy_start_date</th>\n",
       "      <th>customer_feedback</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>exercise_frequency</th>\n",
       "      <th>property_type</th>\n",
       "      <th>premium_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "      <td>1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  gender  annual_income marital_status  number_of_dependents  \\\n",
       "0   0  19.0  Female        10049.0        Married                   1.0   \n",
       "1   1  39.0  Female        31678.0       Divorced                   3.0   \n",
       "2   2  23.0    Male        25602.0       Divorced                   3.0   \n",
       "3   3  21.0    Male       141855.0        Married                   2.0   \n",
       "4   4  21.0    Male        39651.0         Single                   1.0   \n",
       "\n",
       "  education_level     occupation  health_score  location  ... previous_claims  \\\n",
       "0      Bachelor's  Self-Employed     22.598761     Urban  ...             2.0   \n",
       "1        Master's            NaN     15.569731     Rural  ...             1.0   \n",
       "2     High School  Self-Employed     47.177549  Suburban  ...             1.0   \n",
       "3      Bachelor's            NaN     10.938144     Rural  ...             1.0   \n",
       "4      Bachelor's  Self-Employed     20.376094     Rural  ...             0.0   \n",
       "\n",
       "   vehicle_age  credit_score  insurance_duration           policy_start_date  \\\n",
       "0         17.0         372.0                 5.0  2023-12-23 15:21:39.134960   \n",
       "1         12.0         694.0                 2.0  2023-06-12 15:21:39.111551   \n",
       "2         14.0           NaN                 3.0  2023-09-30 15:21:39.221386   \n",
       "3          0.0         367.0                 1.0  2024-06-12 15:21:39.226954   \n",
       "4          8.0         598.0                 4.0  2021-12-01 15:21:39.252145   \n",
       "\n",
       "  customer_feedback smoking_status exercise_frequency property_type  \\\n",
       "0              Poor             No             Weekly         House   \n",
       "1           Average            Yes            Monthly         House   \n",
       "2              Good            Yes             Weekly         House   \n",
       "3              Poor            Yes              Daily     Apartment   \n",
       "4              Poor            Yes             Weekly         House   \n",
       "\n",
       "  premium_amount  \n",
       "0         2869.0  \n",
       "1         1483.0  \n",
       "2          567.0  \n",
       "3          765.0  \n",
       "4         2022.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '') #Just start with cleaning the titles\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "#1.2 million people... no wonder this was such a big file. Realistic considering the industy and what I've worked with\n",
    "#in the past.\n",
    "\n",
    "#Recall that premium is this competion's target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb5926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'annual_income', 'marital_status', 'number_of_dependents',\n",
      "       'occupation', 'health_score', 'previous_claims', 'vehicle_age',\n",
      "       'credit_score', 'insurance_duration', 'customer_feedback'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if sum(df.isnull().sum())==0:\n",
    "    print(\"Phew, no nulls.\")\n",
    "else:\n",
    "    print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e342b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384004, 0.32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For kicks, I want to see if it'd be relevant to just keep 'pure' data:\n",
    "\n",
    "df.dropna(inplace=False).shape[0], round(df.dropna(inplace=False).shape[0]/df.shape[0], 3)\n",
    "\n",
    "#Yeah.... albeit we still have quite a large amount of data, and in most circumstances that's more than enough to work with,\n",
    "#I want to demonstrate null handling for this, hopefully, portfolio-grade project. Might be fun later exploring the\n",
    "#'pure' data: Noticing if the nulls were also consistent.... ie we had an even split of occupation in the overall data,\n",
    "#which is not realistic in real life - does that trend remain in the 'pure' data [and then we may have to do oversampling]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9499c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_sum</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>previous_claims</th>\n",
       "      <td>364029</td>\n",
       "      <td>0.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>358075</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_score</th>\n",
       "      <td>137882</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_dependents</th>\n",
       "      <td>109672</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_feedback</th>\n",
       "      <td>77824</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_score</th>\n",
       "      <td>74076</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>44949</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      null_sum  ratio\n",
       "previous_claims         364029  0.303\n",
       "occupation              358075  0.298\n",
       "credit_score            137882  0.115\n",
       "number_of_dependents    109672  0.091\n",
       "customer_feedback        77824  0.065\n",
       "health_score             74076  0.062\n",
       "annual_income            44949  0.037"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After back and fourth with ChatGPT and I, I figured this approach is better. No need to loop.\n",
    "\n",
    "thresh = .02\n",
    "\n",
    "null_counts = pd.DataFrame({'null_sum': df.isnull().sum()})\n",
    "null_counts['ratio'] = round(null_counts['null_sum']/df.shape[0], 3)\n",
    "null_concerns = null_counts[null_counts['ratio']>thresh].sort_values('ratio', ascending=False)\n",
    "null_concerns\n",
    "\n",
    "#So, previous claims has quite a lot of nulls... and even occupation does. Interesting. I wonder if that's th same as unemployed.\n",
    "#Credit score is always inteesting to see. Dependents are reasonable to ask, as well as feedback. Perhaps some similar issues iwth\n",
    "#health score as well (ie on the surface I'd assume dubious data doesn't have a health score). No comment on income (in the\n",
    "#context of nulls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda00543",
   "metadata": {},
   "source": [
    "## Initial EDA\n",
    "\n",
    "Note that this will be my first projec where I hopefully remember to get into the habit of pasting below into a bit of code to later preserve any changes made to the data to a cleaned csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300559f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82807030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "0          8.333333e-07\n",
       "799988     8.333333e-07\n",
       "800004     8.333333e-07\n",
       "800003     8.333333e-07\n",
       "800002     8.333333e-07\n",
       "               ...     \n",
       "399999     8.333333e-07\n",
       "399998     8.333333e-07\n",
       "399997     8.333333e-07\n",
       "399996     8.333333e-07\n",
       "1199999    8.333333e-07\n",
       "Name: proportion, Length: 1200000, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1 #Eh...\n",
    "print(f\"Now looking at feature {i}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d55892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 1, age.\n",
      "Reminder that age has 18705 nulls (0.016%) - deal with them noob.\n",
      "~~~\n",
      "count    1.181295e+06\n",
      "mean     4.114556e+01\n",
      "std      1.353995e+01\n",
      "min      1.800000e+01\n",
      "25%      3.000000e+01\n",
      "50%      4.100000e+01\n",
      "75%      5.300000e+01\n",
      "max      6.400000e+01\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\") #Potentially redundant, but eh - I like to already see which\n",
    "#feature it is. More intuitive and user-friendly.\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "#See below for commentary, but in short I decided to streamline this bit.\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e43c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed54718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   1,200,000.00\n",
       "mean           41.14\n",
       "std            13.43\n",
       "min            18.00\n",
       "25%            30.00\n",
       "50%            41.00\n",
       "75%            53.00\n",
       "max            64.00\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thanks to ChatGPT re. this neat bit right here.\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df['age'].describe()\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006a33b",
   "metadata": {},
   "source": [
    "Yeah, quite a nice distribution here. Shame it cuts off at 64. Unsurprising that it only starts at 18.\n",
    "\n",
    "Now, immediately I'd want to band as we assume people of similar ages have similar enough characteristics. Furthermore, from an actuarial/rate perspective we'd do that all the time (for that or whatever other reasns). It definitely makes things simpler. I'm pretty sure even after banding we'd still consider specific ages.\n",
    "\n",
    "So, starting from 18-22, simplifying all that to the '20' band.... and we'd likely either make the 60 band, consisting of people (by default) 58-62 to be bigger and also have 63 and 64... or a smaller 'old' band of anybody beyond that. Initially I was inclined a bigger final one, but my current desire is to have a smaller older band at our conclusion: It's flexible to account for a theortical change of data (that go beyond 64), retains spirit of my old work where we'd have a senior category, and it's funny (I plan on calling it 'oldies' or 'dinosaurs').\n",
    "\n",
    "Anyways, essentially normally distributed around 41. Decent standard deviation, but makes sense given stuff (vague)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4834e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_band_names = []\n",
    "for band in range(20,65, 5):\n",
    "    age_band_names.append(band)\n",
    "# print(names)\n",
    "\n",
    "for feature in age_band_names:\n",
    "    cond1 = feature - 2\n",
    "    cond2 = feature + 2\n",
    "    df[str(feature)] = [1 if (age >= cond1 and age <= cond2) else 0 for age in df['age']]\n",
    "\n",
    "#ChatGPT recommended something like this, but eh...\n",
    "# for band in age_band_names[:-1]:  # Handle all except 'dinosaurs'\n",
    "#     lower, upper = map(int, band.split('-'))\n",
    "#     df[band] = ((df['age'] >= lower - 2) & (df['age'] <= upper + 2)).astype(int)\n",
    "    \n",
    "df['dinosaurs'] = (df['age'] > age_band_names[-1]+2).astype(int)#I'll keep their version. And they were right - why bother\n",
    "#adding it earlier then have to deal with exception stuff if it's really just this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b2e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 2, gender.\n",
      "~~~\n",
      "gender\n",
      "Male      0.502143\n",
      "Female    0.497858\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pd.reset_option('display.float_format')\n",
    "\n",
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "\n",
    "#Nice even split. approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96e45265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = [0 if gender == 'Female' else 1 for gender in df['gender']] #Recall that only a definite female\n",
    "#we defined as male, with that gender abosrbing any 'other' - which would include an unknown. Especially in this data\n",
    "#when it'd be the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e73e020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 3, annual_income.\n",
      "Reminder that annual_income has 44949 nulls (0.037%) - deal with them noob.\n",
      "~~~\n",
      "count   1,155,051.00\n",
      "mean       32,745.22\n",
      "std        32,179.51\n",
      "min             1.00\n",
      "25%         8,001.00\n",
      "50%        23,911.00\n",
      "75%        44,634.00\n",
      "max       149,997.00\n",
      "Name: annual_income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e8a9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yeah, I should really keep the filling a seperate cell. Regardless. Let's analyze:\n",
    "#Unexpectedly skewed to the right, with the median quite lower than the mean... Funny what year the date is based off of\n",
    "#given inflation and the like. Regardless, the trend holds true.\n",
    "\n",
    "#I'd expect a strong correlation to health, as by default if they can't even afford healthcare... At the same time, I recall\n",
    "#the quandry of a certain streamer - if you're broke you get it for free and if you're rich it doesn't matter, but all the\n",
    "#middl class.... And, evn thte upper tiers I could imagine depending upon their scenarios.... Ie even 150k is not all hat\n",
    "#much in 2025....\n",
    "\n",
    "df['annual_income'].fillna(df['annual_income'].median(), inplace=True) #Especially when either way I'd want to copy\n",
    "#the code later on - I might as well get into the habit of using the precise name - as opposed to the variable is. Lest\n",
    "#I mess up, want to change something, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d736bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 4, marital_status.\n",
      "Reminder that marital_status has 18529 nulls (0.015%) - deal with them noob.\n",
      "~~~\n",
      "marital_status\n",
      "Single     0.33\n",
      "Married    0.33\n",
      "Divorced   0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb66045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even enough distribution. Shame with the Pandas rounding as I'm sure it's not precise. Hmm, maybe I should just do both?\n",
    "#So, in this case I'd assume single as definitionally they have themselves, so logically it would be the 'baseline'.\n",
    "\n",
    "df['marital_status'].fillna('Single', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf4b8a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 5, number_of_dependents.\n",
      "Reminder that number_of_dependents has 109672 nulls (0.091%) - deal with them noob.\n",
      "~~~\n",
      "number_of_dependents\n",
      "3.00   0.20\n",
      "4.00   0.20\n",
      "0.00   0.20\n",
      "2.00   0.20\n",
      "1.00   0.20\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a691e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll assume 0. Albeit not the median (2) I'd rather not add something when by default I can't prove its existence.\n",
    "#I don't like this wording, but I'm trying to say: Unlike age where they must be something definitionally, there doesn't\n",
    "#have to be dependents. Hence, without proof or any other additional considerations, I'd assume the default of 0.\n",
    "\n",
    "df['number_of_dependents'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64fc1efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 6, education_level.\n",
      "~~~\n",
      "education_level\n",
      "Master's      0.25\n",
      "PhD           0.25\n",
      "Bachelor's    0.25\n",
      "High School   0.24\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Likely because it's synthetic, but eh - I'm not liking these even splits.... Phds should be much smaller... Oh well.\n",
    "#Reminder to dummify (forgot to do that). Not as relevant anymore as we're dummifying at the end.\n",
    "#Oh, hence, what we discussed earlier: Might be a move to have that list. of objects.. oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b43c72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 7, occupation.\n",
      "Reminder that occupation has 358075 nulls (0.298%) - deal with them noob.\n",
      "~~~\n",
      "occupation\n",
      "Employed        0.34\n",
      "Self-Employed   0.34\n",
      "Unemployed      0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4caf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like number of dependents, I'll assume no job.\n",
    "df['occupation'].fillna('Unemployed', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "005e3590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 8, health_score.\n",
      "Reminder that health_score has 74076 nulls (0.062%) - deal with them noob.\n",
      "~~~\n",
      "count   1,125,924.00\n",
      "mean           25.61\n",
      "std            12.20\n",
      "min             2.01\n",
      "25%            15.92\n",
      "50%            24.58\n",
      "75%            34.53\n",
      "max            58.98\n",
      "Name: health_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "\n",
    "#Tangential, but a bit tempted to try something like this:\n",
    "#I'm getting tired of having to rechange the code dep. on the type of feature.\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec39d3a",
   "metadata": {},
   "source": [
    "Tangential (again) but I wonder if for EDA such as this it might be better to just make an initia split of (suspected) categorical and numeric variables and go down with them. Eh... we'll see.\n",
    "\n",
    "Off hand I don't recall a definition of healthscare. However, the point is clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cb95941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['health_score'].fillna(df['health_score'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03578bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 9, location.\n",
      "~~~\n",
      "location\n",
      "Suburban   0.33\n",
      "Rural      0.33\n",
      "Urban      0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "#Seriously, these splits are waaaay too even. One thing if this would be classification and we're talking about our targt,\n",
    "#but for the features.... and every single one? I supposeit is ideal, but I don't want that in my data!!!\n",
    "\n",
    "#Until data gets interesting I won't bother to comment. Ie even if realistically the groups should be skewed in whatever way,\n",
    "#like expecting a minority of Phds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cd2b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 10, policy_type.\n",
      "~~~\n",
      "policy_type\n",
      "Premium         0.33\n",
      "Comprehensive   0.33\n",
      "Basic           0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Would expect and hope premium pays more. Potentialy could make these hierarchical. But, for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3b8702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 11, previous_claims.\n",
      "Reminder that previous_claims has 364029 nulls (0.303%) - deal with them noob.\n",
      "~~~\n",
      "previous_claims\n",
      "0.00   0.37\n",
      "1.00   0.36\n",
      "2.00   0.20\n",
      "3.00   0.06\n",
      "4.00   0.01\n",
      "5.00   0.00\n",
      "6.00   0.00\n",
      "7.00   0.00\n",
      "8.00   0.00\n",
      "9.00   0.00\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8cb2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   835,971.00\n",
      "mean          1.00\n",
      "std           0.98\n",
      "min           0.00\n",
      "25%           0.00\n",
      "50%           1.00\n",
      "75%           2.00\n",
      "max           9.00\n",
      "Name: previous_claims, dtype: float64\n",
      "669462 530538\n"
     ]
    }
   ],
   "source": [
    "#Makes sense to see such a skew, as unlikely for people to have more and more.\n",
    "#Note that the max is actually 9 (well, we know that from our code logic already):\n",
    "print(df['previous_claims'].describe())\n",
    "atleast_1 = sum(df['previous_claims']>0)\n",
    "print(df.shape[0] - atleast_1, atleast_1)\n",
    "\n",
    "#Like before with dependents. See our logic there.\n",
    "df['previous_claims'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670d442",
   "metadata": {},
   "source": [
    "Wow what a mean considering all the 0s. Guess it's not that surprising as the 0s and 1s average out to be .5 then consider all the rest... Regardless, let's see (and comment in this block) if it's at least one:\n",
    "\n",
    "Yeah, then this is quite interesting. Now we see a a hefty skew to the right (before the opposite, albeit not as exagerated). Ie you got those 'unhealthy' people always getting sick. Potentially they didn't get enough care. Regardless, the regulars dominate the activity here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb558ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   530,538.00\n",
       "mean          1.58\n",
       "std           0.78\n",
       "min           1.00\n",
       "25%           1.00\n",
       "50%           1.00\n",
       "75%           2.00\n",
       "max           9.00\n",
       "Name: previous_claims, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['previous_claims']>0]['previous_claims'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ac7e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 12, vehicle_age.\n",
      "Reminder that vehicle_age has 6 nulls (0.0%) - deal with them noob.\n",
      "~~~\n",
      "count   1,199,994.00\n",
      "mean            9.57\n",
      "std             5.78\n",
      "min             0.00\n",
      "25%             5.00\n",
      "50%            10.00\n",
      "75%            15.00\n",
      "max            19.00\n",
      "Name: vehicle_age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "748699b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61615, 0.051)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bit to the lft, but overall nice distribution. Honestly should be expected with this dataset by now...\n",
    "\n",
    "#Of note are these babies - notice how we have only whole numbers so likly they're just very new cars.\n",
    "\n",
    "sum(df['vehicle_age']==0), round(sum(df['vehicle_age']==0)/df.shape[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e9d5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_age'].fillna(df['vehicle_age'].median(), inplace=True) #Like human age must be something. In this case with so\n",
    "#Few nulls though a bit negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96053df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 13, credit_score.\n",
      "Reminder that credit_score has 137882 nulls (0.115%) - deal with them noob.\n",
      "~~~\n",
      "count   1,062,118.00\n",
      "mean          592.92\n",
      "std           149.98\n",
      "min           300.00\n",
      "25%           468.00\n",
      "50%           595.00\n",
      "75%           721.00\n",
      "max           849.00\n",
      "Name: credit_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Again, another clean even (ess.) dist.. Recall that the max is 300 and absolute is 850.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6921efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_score'].fillna(df['credit_score'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4ab9e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Master's      0.26\n",
       "PhD           0.25\n",
       "Bachelor's    0.25\n",
       "High School   0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just for kicks, I want to see how evenly distributed some of the variables are:\n",
    "df[df['credit_score']<350]['education_level'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08361ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "PhD           0.26\n",
       "Bachelor's    0.25\n",
       "Master's      0.25\n",
       "High School   0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['credit_score']>800]['education_level'].value_counts(normalize=True)\n",
    "#Unsurprising...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ab979",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We now fixed this, but regardless:\n",
    "\n",
    "# Oh gf me - forgot to dummify this stuff. Given this last bit of code it might be better to dummify at the end.\n",
    "# Or, do something like keeping the original. Do my EDA, then redo the dummification/actually do it at the end.\n",
    "# Especially when either way we'd need to do so for the test data we might as well not get ourselves confused with that (\n",
    "# recall the +1 potential disasters of our i-scrolling) & avoid this issue [easily compare all of a feature's categories\n",
    "# together].\n",
    "\n",
    "# From ChatGPT I'll sort out later.... Enough of the coding and analysis practice for today.\n",
    "\n",
    "# df['occupation_original'] = df['occupation']  # Preserve original column\n",
    "# df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56965bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_col = df['occupation']\n",
    "# df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "# df.insert(0, 'occupation_original', original_col)  # Insert at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb2956da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 14, insurance_duration.\n",
      "Reminder that insurance_duration has 1 nulls (0.0%) - deal with them noob.\n",
      "~~~\n",
      "insurance_duration\n",
      "9.00   0.11\n",
      "1.00   0.11\n",
      "8.00   0.11\n",
      "7.00   0.11\n",
      "5.00   0.11\n",
      "4.00   0.11\n",
      "6.00   0.11\n",
      "3.00   0.11\n",
      "2.00   0.11\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Unsure if this is in months or years. It also just dawned on me - was this for car data? Would makee sense given the vehicle\n",
    "#age feature. Just assumed it was health. Oh well - all the ideas remain the same....\n",
    "\n",
    "#Hmm, I double chcked th page and I'm honestly not convinced from the page. Awkward... Inclined to still assume health/life though.\n",
    "#Now, does it matter? Potentially not. But that's a discussion for later (likely when we get to premium)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cdb6ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   1,199,999.00\n",
       "mean            5.02\n",
       "std             2.59\n",
       "min             1.00\n",
       "25%             3.00\n",
       "50%             5.00\n",
       "75%             7.00\n",
       "max             9.00\n",
       "Name: insurance_duration, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['insurance_duration'].describe() #Ooh quite a nice distribution. Seriously though, these are all way too organized..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61edecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just one null - replacing it with the median which is approx. the mean...\n",
    "df['insurance_duration'].fillna(5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "468d121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 15, policy_start_date.\n",
      "~~~\n",
      "policy_start_date\n",
      "2020-02-08 15:21:39.134960   0.00\n",
      "2023-08-13 15:21:39.155231   0.00\n",
      "2022-02-02 15:21:39.134960   0.00\n",
      "2022-08-30 15:21:39.134960   0.00\n",
      "2023-11-02 15:21:39.134960   0.00\n",
      "                             ... \n",
      "2021-06-07 15:21:39.104139   0.00\n",
      "2024-07-19 15:21:39.233998   0.00\n",
      "2019-12-14 15:21:39.110557   0.00\n",
      "2020-07-23 15:21:39.217387   0.00\n",
      "2020-10-19 15:21:39.118178   0.00\n",
      "Name: proportion, Length: 167381, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Yeah, we gotta clean the times. Or at least do something (potentially ignore...) with them. For now let's do the easy stuff.\n",
    "#To at least analyze: Month might matter. Day of week/weekend might matter. Time might mater..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea041801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 16, customer_feedback.\n",
      "Reminder that customer_feedback has 77824 nulls (0.065%) - deal with them noob.\n",
      "~~~\n",
      "customer_feedback\n",
      "Average   0.34\n",
      "Poor      0.33\n",
      "Good      0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Unlike education level, likely a lot more justified to map these two numbers: -1, 0, 1 seems the most logical to me.\n",
    "#Still might be worthwhile to dummify like the rest; but I won't.\n",
    "#Ie with education I don't think the advantages of increasing the education are linear (rather diminishing returns after\n",
    "#bachelors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95e150e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_feedback'].fillna('Average', inplace=True)\n",
    "#From ChatGPT for convenience:\n",
    "\n",
    "mapping = {\n",
    "    'Poor': -1,\n",
    "    'Average': 0,\n",
    "    'Good': 1\n",
    "}\n",
    "df['customer_feedback'] = df['customer_feedback'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57b86270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_feedback\n",
       " 0   0.38\n",
       "-1   0.31\n",
       " 1   0.31\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customer_feedback'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c874ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 17, smoking_status.\n",
      "~~~\n",
      "smoking_status\n",
      "Yes   0.50\n",
      "No    0.50\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "#Come on - even by the smokers?!?!? Perhaps weed, heh.\n",
    "#Onn the topic that's actualyl quite interesting - smoking what? Historically would be cigarettes, but in 2025 likely th\n",
    "#percenages of 'smokers' and their relativ changes in health vary quite a lot from drug to drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b436503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smoking_status'] = [0 if status == 'No' else 1 for status in df['smoking_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85bd66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 18, exercise_frequency.\n",
      "~~~\n",
      "exercise_frequency\n",
      "Weekly    0.26\n",
      "Monthly   0.25\n",
      "Rarely    0.25\n",
      "Daily     0.25\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cd3c9",
   "metadata": {},
   "source": [
    "Hmm, likely this should be dummified as I venture the health changes are definitely not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d4ca624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 19, property_type.\n",
      "~~~\n",
      "property_type\n",
      "House       0.33\n",
      "Apartment   0.33\n",
      "Condo       0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "#Perhaps another proxy of stability and healtth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6efba6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 20, premium_amount.\n",
      "~~~\n",
      "count   1,200,000.00\n",
      "mean        1,102.54\n",
      "std           865.00\n",
      "min            20.00\n",
      "25%           514.00\n",
      "50%           872.00\n",
      "75%         1,509.00\n",
      "max         4,999.00\n",
      "Name: premium_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a99aaa4",
   "metadata": {},
   "source": [
    "And now our long awaited target - premium.\n",
    "\n",
    "Nice to finally see a non-normal distrubtion. Notice th hefty skew to the right of quite a larger mean than median. Furthermor, look at that standard deviation - almost as large as the median itself! So, unsurprisingly we see a few people paying a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2feb0ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phew, no nulls.\n"
     ]
    }
   ],
   "source": [
    "#Conf. that I got them all.\n",
    "if sum(df.isnull().sum())==0:\n",
    "    print(\"Phew, no nulls.\")\n",
    "else:\n",
    "    print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88743b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "361b712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy section, as we want to keep th categories as strings/objects at the moment for easier eda\n",
    "\n",
    "df = pd.get_dummies(df, columns=['marital_status'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['education_level'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['location'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['policy_type'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['exercise_frequency'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['property_type'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd311c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>health_score</th>\n",
       "      <th>previous_claims</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>insurance_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_Unemployed</th>\n",
       "      <th>location_Suburban</th>\n",
       "      <th>location_Urban</th>\n",
       "      <th>policy_type_Comprehensive</th>\n",
       "      <th>policy_type_Premium</th>\n",
       "      <th>exercise_frequency_Monthly</th>\n",
       "      <th>exercise_frequency_Rarely</th>\n",
       "      <th>exercise_frequency_Weekly</th>\n",
       "      <th>property_type_Condo</th>\n",
       "      <th>property_type_House</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10,049.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>22.60</td>\n",
       "      <td>2.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0</td>\n",
       "      <td>31,678.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>694.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1</td>\n",
       "      <td>25,602.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>47.18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>595.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1</td>\n",
       "      <td>141,855.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>367.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1</td>\n",
       "      <td>39,651.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>598.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  gender  annual_income  number_of_dependents  health_score  \\\n",
       "0   0 19.00       0      10,049.00                  1.00         22.60   \n",
       "1   1 39.00       0      31,678.00                  3.00         15.57   \n",
       "2   2 23.00       1      25,602.00                  3.00         47.18   \n",
       "3   3 21.00       1     141,855.00                  2.00         10.94   \n",
       "4   4 21.00       1      39,651.00                  1.00         20.38   \n",
       "\n",
       "   previous_claims  vehicle_age  credit_score  insurance_duration  ...  \\\n",
       "0             2.00        17.00        372.00                5.00  ...   \n",
       "1             1.00        12.00        694.00                2.00  ...   \n",
       "2             1.00        14.00        595.00                3.00  ...   \n",
       "3             1.00         0.00        367.00                1.00  ...   \n",
       "4             0.00         8.00        598.00                4.00  ...   \n",
       "\n",
       "  occupation_Unemployed  location_Suburban  location_Urban  \\\n",
       "0                     0                  0               1   \n",
       "1                     1                  0               0   \n",
       "2                     0                  1               0   \n",
       "3                     1                  0               0   \n",
       "4                     0                  0               0   \n",
       "\n",
       "   policy_type_Comprehensive  policy_type_Premium  exercise_frequency_Monthly  \\\n",
       "0                          0                    1                           0   \n",
       "1                          1                    0                           1   \n",
       "2                          0                    1                           0   \n",
       "3                          0                    0                           0   \n",
       "4                          0                    1                           0   \n",
       "\n",
       "   exercise_frequency_Rarely  exercise_frequency_Weekly  property_type_Condo  \\\n",
       "0                          0                          1                    0   \n",
       "1                          0                          0                    0   \n",
       "2                          0                          1                    0   \n",
       "3                          0                          0                    0   \n",
       "4                          0                          1                    0   \n",
       "\n",
       "   property_type_House  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be235f",
   "metadata": {},
   "source": [
    "## Concluding Matters\n",
    "\n",
    "Hmm, from an efficiency standpoint I wonder if it's better to not even change the original data and just post here, even for the train data, all the various changes - just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8500f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623467c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annual_income'].fillna(df['annual_income'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a627d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As I said earlier, prepping the total changed cleanings for modeling.\n",
    "#Ie kind of like on Git we have the commit before actually pushing.\n",
    "df = pd.read_csv('../data/train_data.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '')\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = round(df[col], 3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "age_band_names = []\n",
    "for band in range(20,65, 5):\n",
    "    age_band_names.append(band)\n",
    "for feature in age_band_names:\n",
    "    cond1 = feature - 2\n",
    "    cond2 = feature + 2\n",
    "    df[str(feature)] = [1 if (age >= cond1 and age <= cond2) else 0 for age in df['age']]\n",
    "df['dinosaurs'] = (df['age'] > age_band_names[-1]+2).astype(int)\n",
    "\n",
    "df['gender'] = [0 if gender == 'Female' else 1 for gender in df['gender']]\n",
    "\n",
    "df['annual_income'].fillna(df['annual_income'].median(), inplace=True)\n",
    "\n",
    "df['marital_status'].fillna('Single', inplace=True)\n",
    "\n",
    "df['number_of_dependents'].fillna(0, inplace=True)\n",
    "\n",
    "df['occupation'].fillna('Unemployed', inplace=True)\n",
    "\n",
    "df['health_score'].fillna(df['health_score'].median(), inplace=True)\n",
    "\n",
    "df['previous_claims'].fillna(0, inplace=True)\n",
    "\n",
    "df['vehicle_age'].fillna(df['vehicle_age'].median(), inplace=True)\n",
    "\n",
    "df['credit_score'].fillna(df['credit_score'].median(), inplace=True)\n",
    "\n",
    "df['insurance_duration'].fillna(5, inplace=True)\n",
    "\n",
    "df['customer_feedback'].fillna('Average', inplace=True)\n",
    "mapping = {\n",
    "    'Poor': -1,\n",
    "    'Average': 0,\n",
    "    'Good': 1\n",
    "}\n",
    "df['customer_feedback'] = df['customer_feedback'].map(mapping)\n",
    "\n",
    "df['smoking_status'] = [0 if status == 'No' else 1 for status in df['smoking_status']]\n",
    "\n",
    "if sum(df.isnull().sum())==0:\n",
    "    print(\"Phew, no nulls.\")\n",
    "else:\n",
    "    print(df.columns[df.isnull().any()])\n",
    "\n",
    "#Dummies now:\n",
    "df = pd.get_dummies(df, columns=['marital_status'], dtype=int, drop_frst=True)\n",
    "df = pd.get_dummies(df, columns=['education_level'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['location'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['policy_type'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['exercise_frequency'], dtype=int, drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['property_type'], dtype=int, drop_first=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
