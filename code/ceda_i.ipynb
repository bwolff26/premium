{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb94d17",
   "metadata": {},
   "source": [
    "As usual we're start with cleaning and attempt to delay EDA until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d28c57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d75d5f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>10,049.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.60</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2,869.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>31,678.00</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.57</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>694.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "      <td>1,483.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>25,602.00</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.00</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>47.18</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>567.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>141,855.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.94</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>367.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>765.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>39,651.00</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.38</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>598.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2,022.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   Age  Gender  Annual Income Marital Status  Number of Dependents  \\\n",
       "0   0 19.00  Female      10,049.00        Married                  1.00   \n",
       "1   1 39.00  Female      31,678.00       Divorced                  3.00   \n",
       "2   2 23.00    Male      25,602.00       Divorced                  3.00   \n",
       "3   3 21.00    Male     141,855.00        Married                  2.00   \n",
       "4   4 21.00    Male      39,651.00         Single                  1.00   \n",
       "\n",
       "  Education Level     Occupation  Health Score  Location  ... Previous Claims  \\\n",
       "0      Bachelor's  Self-Employed         22.60     Urban  ...            2.00   \n",
       "1        Master's            NaN         15.57     Rural  ...            1.00   \n",
       "2     High School  Self-Employed         47.18  Suburban  ...            1.00   \n",
       "3      Bachelor's            NaN         10.94     Rural  ...            1.00   \n",
       "4      Bachelor's  Self-Employed         20.38     Rural  ...            0.00   \n",
       "\n",
       "   Vehicle Age  Credit Score  Insurance Duration           Policy Start Date  \\\n",
       "0        17.00        372.00                5.00  2023-12-23 15:21:39.134960   \n",
       "1        12.00        694.00                2.00  2023-06-12 15:21:39.111551   \n",
       "2        14.00           NaN                3.00  2023-09-30 15:21:39.221386   \n",
       "3         0.00        367.00                1.00  2024-06-12 15:21:39.226954   \n",
       "4         8.00        598.00                4.00  2021-12-01 15:21:39.252145   \n",
       "\n",
       "  Customer Feedback Smoking Status Exercise Frequency Property Type  \\\n",
       "0              Poor             No             Weekly         House   \n",
       "1           Average            Yes            Monthly         House   \n",
       "2              Good            Yes             Weekly         House   \n",
       "3              Poor            Yes              Daily     Apartment   \n",
       "4              Poor            Yes             Weekly         House   \n",
       "\n",
       "  Premium Amount  \n",
       "0       2,869.00  \n",
       "1       1,483.00  \n",
       "2         567.00  \n",
       "3         765.00  \n",
       "4       2,022.00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "#1.2 million people... no wonder this was such a big file. Realistic considering the industy and what I've worked with\n",
    "#in the past.\n",
    "\n",
    "#Recall that premium is this competion's target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7107e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecb5926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'annual_income', 'marital_status', 'number_of_dependents',\n",
      "       'occupation', 'health_score', 'previous_claims', 'vehicle_age',\n",
      "       'credit_score', 'insurance_duration', 'customer_feedback'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if sum(df.isnull().sum())==0:\n",
    "    print(\"Phew, no nulls.\")\n",
    "else:\n",
    "    print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c9499c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_sum</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>previous_claims</th>\n",
       "      <td>364029</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>358075</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_score</th>\n",
       "      <td>137882</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_dependents</th>\n",
       "      <td>109672</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_feedback</th>\n",
       "      <td>77824</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_score</th>\n",
       "      <td>74076</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>44949</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      null_sum  ratio\n",
       "previous_claims         364029   0.30\n",
       "occupation              358075   0.30\n",
       "credit_score            137882   0.12\n",
       "number_of_dependents    109672   0.09\n",
       "customer_feedback        77824   0.07\n",
       "health_score             74076   0.06\n",
       "annual_income            44949   0.04"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After back and fourth with ChatGPT and I, I figured this approach is better. No need to loop.\n",
    "\n",
    "thresh = .02\n",
    "\n",
    "null_counts = pd.DataFrame({'null_sum': df.isnull().sum()})\n",
    "null_counts['ratio'] = round(null_counts['null_sum']/df.shape[0], 3)\n",
    "null_concerns = null_counts[null_counts['ratio']>thresh].sort_values('ratio', ascending=False)\n",
    "null_concerns\n",
    "\n",
    "#So, previous claims has quite a lot of nulls... and even occupation does. Interesting. I wonder if that's th same as unemployed.\n",
    "#Credit score is always inteesting to see. Dependents are reasonable to ask, as well as feedback. Perhaps some similar issues iwth\n",
    "#health score as well (ie on the surface I'd assume dubious data doesn't have a health score). No comment on income (in the\n",
    "#context of nulls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda00543",
   "metadata": {},
   "source": [
    "## Initial EDA\n",
    "\n",
    "Note that this will be my first projec where I hopefully remember to get into the habit of pasting below into a bit of code to later preserve any changes made to the data to a cleaned csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "300559f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82807030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "0         0.00\n",
       "799988    0.00\n",
       "800004    0.00\n",
       "800003    0.00\n",
       "800002    0.00\n",
       "          ... \n",
       "399999    0.00\n",
       "399998    0.00\n",
       "399997    0.00\n",
       "399996    0.00\n",
       "1199999   0.00\n",
       "Name: proportion, Length: 1200000, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1 #Eh...\n",
    "print(f\"Now looking at feature {i}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26d55892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 1, age.\n",
      "Reminder that age has 18705 nulls (0.016%) - deal with them noob.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age\n",
       "53.00   0.02\n",
       "61.00   0.02\n",
       "39.00   0.02\n",
       "64.00   0.02\n",
       "57.00   0.02\n",
       "43.00   0.02\n",
       "62.00   0.02\n",
       "46.00   0.02\n",
       "33.00   0.02\n",
       "47.00   0.02\n",
       "44.00   0.02\n",
       "34.00   0.02\n",
       "58.00   0.02\n",
       "31.00   0.02\n",
       "56.00   0.02\n",
       "32.00   0.02\n",
       "54.00   0.02\n",
       "38.00   0.02\n",
       "36.00   0.02\n",
       "35.00   0.02\n",
       "22.00   0.02\n",
       "59.00   0.02\n",
       "37.00   0.02\n",
       "51.00   0.02\n",
       "55.00   0.02\n",
       "49.00   0.02\n",
       "45.00   0.02\n",
       "20.00   0.02\n",
       "21.00   0.02\n",
       "50.00   0.02\n",
       "40.00   0.02\n",
       "48.00   0.02\n",
       "26.00   0.02\n",
       "24.00   0.02\n",
       "30.00   0.02\n",
       "29.00   0.02\n",
       "19.00   0.02\n",
       "42.00   0.02\n",
       "60.00   0.02\n",
       "52.00   0.02\n",
       "18.00   0.02\n",
       "28.00   0.02\n",
       "63.00   0.02\n",
       "25.00   0.02\n",
       "27.00   0.02\n",
       "41.00   0.02\n",
       "23.00   0.02\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\") #Potentially redundant, but eh - I like to already see which\n",
    "#feature it is. More intuitive and user-friendly.\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e43c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[i]].fillna(df[df.columns[i]].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ed54718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   1,200,000.00\n",
       "mean           41.14\n",
       "std            13.43\n",
       "min            18.00\n",
       "25%            30.00\n",
       "50%            41.00\n",
       "75%            53.00\n",
       "max            64.00\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thanks to ChatGPT re. this neat bit right here.\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df['age'].describe()\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006a33b",
   "metadata": {},
   "source": [
    "Yeah, quite a nice distribution here. Shame it cuts off at 64. Unsurprising that it only starts at 18.\n",
    "\n",
    "Now, immediately I'd want to band as we assume people of similar ages have similar enough characteristics. Furthermore, from an actuarial/rate perspective we'd do that all the time (for that or whatever other reasns). It definitely makes things simpler. I'm pretty sure even after banding we'd still consider specific ages.\n",
    "\n",
    "So, starting from 18-22, simplifying all that to the '20' band.... and we'd likely either make the 60 band, consisting of people (by default) 58-62 to be bigger and also have 63 and 64... or a smaller 'old' band of anybody beyond that. Initially I was inclined a bigger final one, but my current desire is to have a smaller older band at our conclusion: It's flexible to account for a theortical change of data (that go beyond 64), retains spirit of my old work where we'd have a senior category, and it's funny (I plan on calling it 'oldies' or 'dinosaurs').\n",
    "\n",
    "Anyways, essentially normally distributed around 41. Decent standard deviation, but makes sense given stuff (vague)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4834e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_band_names = []\n",
    "for band in range(20,65, 5):\n",
    "    age_band_names.append(band)\n",
    "# print(names)\n",
    "\n",
    "for feature in age_band_names:\n",
    "    cond1 = feature - 2\n",
    "    cond2 = feature + 2\n",
    "    df[str(feature)] = [1 if (age >= cond1 and age <= cond2) else 0 for age in df['age']]\n",
    "\n",
    "#ChatGPT recommended something like this, but eh...\n",
    "# for band in age_band_names[:-1]:  # Handle all except 'dinosaurs'\n",
    "#     lower, upper = map(int, band.split('-'))\n",
    "#     df[band] = ((df['age'] >= lower - 2) & (df['age'] <= upper + 2)).astype(int)\n",
    "    \n",
    "df['dinosaurs'] = (df['age'] > age_band_names[-1]+2).astype(int)#I'll keep their version. And they were right - why bother\n",
    "#adding it earlier then have to deal with exception stuff if it's really just this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6b2e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 2, gender.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Male      0.502143\n",
       "Female    0.497858\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.reset_option('display.float_format')\n",
    "\n",
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)\n",
    "\n",
    "#Nice even split. approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96e45265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = [0 if gender == 'Female' else 1 for gender in df['gender']] #Recall that only a definite female\n",
    "#we defined as male, with that gender abosrbing any 'other' - which would include an unknown. Especially in this data\n",
    "#when it'd be the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e73e020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 3, annual_income.\n",
      "Reminder that annual_income has 44949 nulls (0.037%) - deal with them noob.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count   1,155,051.00\n",
       "mean       32,745.22\n",
       "std        32,179.51\n",
       "min             1.00\n",
       "25%         8,001.00\n",
       "50%        23,911.00\n",
       "75%        44,634.00\n",
       "max       149,997.00\n",
       "Name: annual_income, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e8a9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yeah, I should really keep the filling a seperate cell. Regardless. Let's analyze:\n",
    "#Unexpectedly skewed to the right, with the median quite lower than the mean... Funny what year the date is based off of\n",
    "#given inflation and the like. Regardless, the trend holds true.\n",
    "\n",
    "#I'd expect a strong correlation to health, as by default if they can't even afford healthcare... At the same time, I recall\n",
    "#the quandry of a certain streamer - if you're broke you get it for free and if you're rich it doesn't matter, but all the\n",
    "#middl class.... And, evn thte upper tiers I could imagine depending upon their scenarios.... Ie even 150k is not all hat\n",
    "#much in 2025....\n",
    "\n",
    "df['annual_income'].fillna(df['annual_income'].median(), inplace=True) #Especially when either way I'd want to copy\n",
    "#the code later on - I might as well get into the habit of using the precise name - as opposed to the variable is. Lest\n",
    "#I mess up, want to change something, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d736bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 4, marital_status.\n",
      "Reminder that marital_status has 18529 nulls (0.015%) - deal with them noob.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "marital_status\n",
       "Single     0.33\n",
       "Married    0.33\n",
       "Divorced   0.33\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbb66045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even enough distribution. Shame with the Pandas rounding as I'm sure it's not precise. Hmm, maybe I should just do both?\n",
    "#So, in this case I'd assume single as definitionally they have themselves, so logically it would be the 'baseline'.\n",
    "\n",
    "df['marital_status'].fillna('Single', inplace=True)\n",
    "df = pd.get_dummies(df, columns=['marital_status'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf4b8a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 4, number_of_dependents.\n",
      "Reminder that number_of_dependents has 109672 nulls (0.091%) - deal with them noob.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "number_of_dependents\n",
       "3.00   0.20\n",
       "4.00   0.20\n",
       "0.00   0.20\n",
       "2.00   0.20\n",
       "1.00   0.20\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Guess I'll be lazy and not delete this line whenever I get rid of the i += 1 per a dummifying.\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a691e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll assume 0. Albeit not the median (2) I'd rather not add something when by default I can't prove its existence.\n",
    "#I don't like this wording, but I'm trying to say: Unlike age where they must be something definitionally, there doesn't\n",
    "#have to be dependents. Hence, without proof or any other additional considerations, I'd assume the default of 0.\n",
    "\n",
    "df['number_of_dependents'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64fc1efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 5, education_level.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Master's      0.25\n",
       "PhD           0.25\n",
       "Bachelor's    0.25\n",
       "High School   0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)\n",
    "#Likely because it's synthetic, but eh - I'm not liking these even splits.... Phds should be much smaller... Oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b43c72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 6, occupation.\n",
      "Reminder that occupation has 358075 nulls (0.298%) - deal with them noob.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "Employed        0.34\n",
       "Self-Employed   0.34\n",
       "Unemployed      0.33\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4caf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like number of dependents, I'll assume no job.\n",
    "df['occupation'].fillna('Unemployed', inplace=True)\n",
    "df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "005e3590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 6, health_score.\n",
      "Reminder that health_score has 74076 nulls (0.062%) - deal with them noob.\n",
      "~~~\n",
      "count   1,125,924.00\n",
      "mean           25.61\n",
      "std            12.20\n",
      "min             2.01\n",
      "25%            15.92\n",
      "50%            24.58\n",
      "75%            34.53\n",
      "max            58.98\n",
      "Name: health_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "\n",
    "#Tangential, but a bit tempted to try something like this:\n",
    "#I'm getting tired of having to rechange the code dep. on the type of feature.\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec39d3a",
   "metadata": {},
   "source": [
    "Tangential (again) but I wonder if for EDA such as this it might be better to just make an initia split of (suspected) categorical and numeric variables and go down with them. Eh... we'll see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9cb95941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['health_score'].fillna(df['health_score'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03578bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 7, location.\n",
      "~~~\n",
      "location\n",
      "Suburban   0.33\n",
      "Rural      0.33\n",
      "Urban      0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "#Seriously, these splits are waaaay too even. One thing if this would be classification and we're talking about our targt,\n",
    "#but for the features.... and every single one? I supposeit is ideal, but I don't want that in my data!!!\n",
    "\n",
    "#Until data gets interesting I won't bother to comment. Ie even if realistically the groups should be skewed in whatever way,\n",
    "#like expecting a minority of Phds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4cd2b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 8, policy_type.\n",
      "~~~\n",
      "policy_type\n",
      "Premium         0.33\n",
      "Comprehensive   0.33\n",
      "Basic           0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3b8702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 9, previous_claims.\n",
      "Reminder that previous_claims has 364029 nulls (0.303%) - deal with them noob.\n",
      "~~~\n",
      "previous_claims\n",
      "0.00   0.37\n",
      "1.00   0.36\n",
      "2.00   0.20\n",
      "3.00   0.06\n",
      "4.00   0.01\n",
      "5.00   0.00\n",
      "6.00   0.00\n",
      "7.00   0.00\n",
      "8.00   0.00\n",
      "9.00   0.00\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8cb2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1,200,000.00\n",
      "mean            0.70\n",
      "std             0.94\n",
      "min             0.00\n",
      "25%             0.00\n",
      "50%             0.00\n",
      "75%             1.00\n",
      "max             9.00\n",
      "Name: previous_claims, dtype: float64\n",
      "669462 530538\n"
     ]
    }
   ],
   "source": [
    "#Makes sense to see such a skew, as unlikely for people to have more and more.\n",
    "#Note that the max is actually 9 (well, we know that from our code logic already):\n",
    "print(df['previous_claims'].describe())\n",
    "atleast_1 = sum(df['previous_claims']>0)\n",
    "print(df.shape[0] - atleast_1, atleast_1)\n",
    "\n",
    "#Like before with dependents. See our logic there.\n",
    "df['previous_claims'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670d442",
   "metadata": {},
   "source": [
    "Wow what a mean considering all the 0s. Guess it's not that surprising as the 0s and 1s average out to be .5 then consider all the rest... Regardless, let's see (and comment in this block) if it's at least one:\n",
    "\n",
    "Yeah, then this is quite interesting. Now we see a a hefty skew to the right (before the opposite, albeit not as exagerated). Ie you got those 'unhealthy' people always getting sick. Potentially they didn't get enough care. Regardless, the regulars dominate the activity here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb558ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   530,538.00\n",
       "mean          1.58\n",
       "std           0.78\n",
       "min           1.00\n",
       "25%           1.00\n",
       "50%           1.00\n",
       "75%           2.00\n",
       "max           9.00\n",
       "Name: previous_claims, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['previous_claims']>0]['previous_claims'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ac7e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 10, vehicle_age.\n",
      "Reminder that vehicle_age has 6 nulls (0.0%) - deal with them noob.\n",
      "~~~\n",
      "count   1,199,994.00\n",
      "mean            9.57\n",
      "std             5.78\n",
      "min             0.00\n",
      "25%             5.00\n",
      "50%            10.00\n",
      "75%            15.00\n",
      "max            19.00\n",
      "Name: vehicle_age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "748699b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61615, 0.051)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bit to the lft, but overall nice distribution. Honestly should be expected with this dataset by now...\n",
    "\n",
    "#Of note are these babies - notice how we have only whole numbers so likly they're just very new cars.\n",
    "\n",
    "sum(df['vehicle_age']==0), round(sum(df['vehicle_age']==0)/df.shape[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3e9d5717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         17.00\n",
       "1         12.00\n",
       "2         14.00\n",
       "3          0.00\n",
       "4          8.00\n",
       "           ... \n",
       "1199995    5.00\n",
       "1199996   10.00\n",
       "1199997   19.00\n",
       "1199998    7.00\n",
       "1199999   18.00\n",
       "Name: vehicle_age, Length: 1200000, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_age'].fillna(df['vehicle_age'].median(), inplace=True) #Like human age must be something. In this case with so\n",
    "#Few nulls though a bit negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96053df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 11, credit_score.\n",
      "Reminder that credit_score has 137882 nulls (0.115%) - deal with them noob.\n",
      "~~~\n",
      "count   1,062,118.00\n",
      "mean          592.92\n",
      "std           149.98\n",
      "min           300.00\n",
      "25%           468.00\n",
      "50%           595.00\n",
      "75%           721.00\n",
      "max           849.00\n",
      "Name: credit_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Again, another clean even (ess.) dist.. Recall that the max is 300 and absolute is 850.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6921efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_score'].fillna(df['credit_score'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e4ab9e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Master's      0.26\n",
       "PhD           0.25\n",
       "Bachelor's    0.25\n",
       "High School   0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just for kicks, I want to see how evenly distributed some of the variables are:\n",
    "df[df['credit_score']<350]['education_level'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "08361ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "PhD           0.26\n",
       "Bachelor's    0.25\n",
       "Master's      0.25\n",
       "High School   0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['credit_score']>800]['education_level'].value_counts(normalize=True)\n",
    "#Unsurprising...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ab979",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oh gf me - forgot to dummify this stuff. Given this last bit of code it might be better to dummify at the end.\n",
    "Or, do something like keeping the original. Do my EDA, then redo the dummification/actually do it at the end.\n",
    "Especially when either way we'd need to do so for the test data we might as well not get ourselves confused with that (\n",
    "recall the +1 potential disasters of our i-scrolling) & avoid this issue [easily compare all of a feature's categories\n",
    "together].\n",
    "\n",
    "From ChatGPT I'll sort out later.... Enough of the coding and analysis practice for today.\n",
    "\n",
    "df['occupation_original'] = df['occupation']  # Preserve original column\n",
    "df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56965bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_col = df['occupation']\n",
    "df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "df.insert(0, 'occupation_original', original_col)  # Insert at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2956da",
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be235f",
   "metadata": {},
   "source": [
    "## Concluding Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8500f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623467c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annual_income'].fillna(df['annual_income'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a627d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As I said earlier, prepping the total changed cleanings for modeling.\n",
    "#Ie kind of like on Git we have the commit before actually pushing.\n",
    "df = pd.read_csv('../data/train_data.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '')\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = round(df[col], 3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "age_band_names = []\n",
    "for band in range(20,65, 5):\n",
    "    age_band_names.append(band)\n",
    "for feature in age_band_names:\n",
    "    cond1 = feature - 2\n",
    "    cond2 = feature + 2\n",
    "    df[str(feature)] = [1 if (age >= cond1 and age <= cond2) else 0 for age in df['age']]\n",
    "df['dinosaurs'] = (df['age'] > age_band_names[-1]+2).astype(int)\n",
    "\n",
    "df['gender'] = [0 if gender == 'Female' else 1 for gender in df['gender']]\n",
    "\n",
    "df['annual_income'].fillna(df['annual_income'].median(), inplace=True)\n",
    "\n",
    "df['marital_status'].fillna('Single', inplace=True)\n",
    "df = pd.get_dummies(df, columns=['marital_status'], dtype=int, drop_first=True)\n",
    "\n",
    "df['number_of_dependents'].fillna(0, inplace=True)\n",
    "\n",
    "df['occupation'].fillna('Unemployed', inplace=True)\n",
    "df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "\n",
    "df['health_score'].fillna(df['health_score'].median(), inplace=True)\n",
    "\n",
    "df['previous_claims'].fillna(0, inplace=True)\n",
    "\n",
    "df['vehicle_age'].fillna(df['vehicle_age'].median(), inplace=True)\n",
    "\n",
    "df['credit_score'].fillna(df['credit_score'].median(), inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
