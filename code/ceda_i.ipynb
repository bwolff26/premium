{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb94d17",
   "metadata": {},
   "source": [
    "As usual we're start with cleaning and attempt to delay EDA until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28c57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75d5f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>education_level</th>\n",
       "      <th>occupation</th>\n",
       "      <th>health_score</th>\n",
       "      <th>location</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>previous_claims</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>insurance_duration</th>\n",
       "      <th>policy_start_date</th>\n",
       "      <th>customer_feedback</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>exercise_frequency</th>\n",
       "      <th>property_type</th>\n",
       "      <th>premium_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "      <td>1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Premium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  gender  annual_income marital_status  number_of_dependents  \\\n",
       "0   0  19.0  Female        10049.0        Married                   1.0   \n",
       "1   1  39.0  Female        31678.0       Divorced                   3.0   \n",
       "2   2  23.0    Male        25602.0       Divorced                   3.0   \n",
       "3   3  21.0    Male       141855.0        Married                   2.0   \n",
       "4   4  21.0    Male        39651.0         Single                   1.0   \n",
       "\n",
       "  education_level     occupation  health_score  location    policy_type  \\\n",
       "0      Bachelor's  Self-Employed     22.598761     Urban        Premium   \n",
       "1        Master's            NaN     15.569731     Rural  Comprehensive   \n",
       "2     High School  Self-Employed     47.177549  Suburban        Premium   \n",
       "3      Bachelor's            NaN     10.938144     Rural          Basic   \n",
       "4      Bachelor's  Self-Employed     20.376094     Rural        Premium   \n",
       "\n",
       "   previous_claims  vehicle_age  credit_score  insurance_duration  \\\n",
       "0              2.0         17.0         372.0                 5.0   \n",
       "1              1.0         12.0         694.0                 2.0   \n",
       "2              1.0         14.0           NaN                 3.0   \n",
       "3              1.0          0.0         367.0                 1.0   \n",
       "4              0.0          8.0         598.0                 4.0   \n",
       "\n",
       "            policy_start_date customer_feedback smoking_status  \\\n",
       "0  2023-12-23 15:21:39.134960              Poor             No   \n",
       "1  2023-06-12 15:21:39.111551           Average            Yes   \n",
       "2  2023-09-30 15:21:39.221386              Good            Yes   \n",
       "3  2024-06-12 15:21:39.226954              Poor            Yes   \n",
       "4  2021-12-01 15:21:39.252145              Poor            Yes   \n",
       "\n",
       "  exercise_frequency property_type  premium_amount  \n",
       "0             Weekly         House          2869.0  \n",
       "1            Monthly         House          1483.0  \n",
       "2             Weekly         House           567.0  \n",
       "3              Daily     Apartment           765.0  \n",
       "4             Weekly         House          2022.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '') #Just start with cleaning the titles\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "#1.2 million people... no wonder this was such a big file. Realistic considering the industy and what I've worked with\n",
    "#in the past.\n",
    "\n",
    "#Recall that premium is this competion's target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb5926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'annual_income', 'marital_status', 'number_of_dependents',\n",
      "       'occupation', 'health_score', 'previous_claims', 'vehicle_age',\n",
      "       'credit_score', 'insurance_duration', 'customer_feedback'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if sum(df.isnull().sum())==0:\n",
    "    print(\"Phew, no nulls.\")\n",
    "else:\n",
    "    print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e342b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384004, 0.32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For kicks, I want to see if it'd be relevant to just keep 'pure' data:\n",
    "\n",
    "df.dropna(inplace=False).shape[0], round(df.dropna(inplace=False).shape[0]/df.shape[0], 3)\n",
    "\n",
    "#Yeah.... albeit we still have quite a large amount of data, and in most circumstances that's more than enough to work with,\n",
    "#I want to demonstrate null handling for this, hopefully, portfolio-grade project. Might be fun later exploring the\n",
    "#'pure' data: Noticing if the nulls were also consistent.... ie we had an even split of occupation in the overall data,\n",
    "#which is not realistic in real life - does that trend remain in the 'pure' data [and then we may have to do oversampling]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9499c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_sum</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>previous_claims</th>\n",
       "      <td>364029</td>\n",
       "      <td>0.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>358075</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_score</th>\n",
       "      <td>137882</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_dependents</th>\n",
       "      <td>109672</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_feedback</th>\n",
       "      <td>77824</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_score</th>\n",
       "      <td>74076</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>44949</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      null_sum  ratio\n",
       "previous_claims         364029  0.303\n",
       "occupation              358075  0.298\n",
       "credit_score            137882  0.115\n",
       "number_of_dependents    109672  0.091\n",
       "customer_feedback        77824  0.065\n",
       "health_score             74076  0.062\n",
       "annual_income            44949  0.037"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After back and fourth with ChatGPT and I, I figured this approach is better. No need to loop.\n",
    "\n",
    "thresh = .02\n",
    "\n",
    "null_counts = pd.DataFrame({'null_sum': df.isnull().sum()})\n",
    "null_counts['ratio'] = round(null_counts['null_sum']/df.shape[0], 3)\n",
    "null_concerns = null_counts[null_counts['ratio']>thresh].sort_values('ratio', ascending=False)\n",
    "null_concerns\n",
    "\n",
    "#So, previous claims has quite a lot of nulls... and even occupation does. Interesting. I wonder if that's th same as unemployed.\n",
    "#Credit score is always inteesting to see. Dependents are reasonable to ask, as well as feedback. Perhaps some similar issues iwth\n",
    "#health score as well (ie on the surface I'd assume dubious data doesn't have a health score). No comment on income (in the\n",
    "#context of nulls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda00543",
   "metadata": {},
   "source": [
    "## Initial EDA\n",
    "\n",
    "Note that this will be my first projec where I hopefully remember to get into the habit of pasting below into a bit of code to later preserve any changes made to the data to a cleaned csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3051e9d",
   "metadata": {},
   "source": [
    "Yeah, I'll keep it as is for now, howver next project I won't bother doing the various changes (null-filling, potential outlier trimming, etc.) until the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300559f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82807030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "0          8.333333e-07\n",
       "799988     8.333333e-07\n",
       "800004     8.333333e-07\n",
       "800003     8.333333e-07\n",
       "800002     8.333333e-07\n",
       "               ...     \n",
       "399999     8.333333e-07\n",
       "399998     8.333333e-07\n",
       "399997     8.333333e-07\n",
       "399996     8.333333e-07\n",
       "1199999    8.333333e-07\n",
       "Name: proportion, Length: 1200000, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1 #Eh...\n",
    "print(f\"Now looking at feature {i}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "df[df.columns[i]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d55892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 1, age.\n",
      "Reminder that age has 18705 nulls (0.016%) - deal with them noob.\n",
      "~~~\n",
      "count    1.181295e+06\n",
      "mean     4.114556e+01\n",
      "std      1.353995e+01\n",
      "min      1.800000e+01\n",
      "25%      3.000000e+01\n",
      "50%      4.100000e+01\n",
      "75%      5.300000e+01\n",
      "max      6.400000e+01\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\") #Potentially redundant, but eh - I like to already see which\n",
    "#feature it is. More intuitive and user-friendly.\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "#See below for commentary, but in short I decided to streamline this bit.\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e43c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed54718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   1,200,000.00\n",
       "mean           41.14\n",
       "std            13.43\n",
       "min            18.00\n",
       "25%            30.00\n",
       "50%            41.00\n",
       "75%            53.00\n",
       "max            64.00\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thanks to ChatGPT re. this neat bit right here.\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df['age'].describe()\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006a33b",
   "metadata": {},
   "source": [
    "Yeah, quite a nice distribution here. Shame it cuts off at 64. Unsurprising that it only starts at 18.\n",
    "\n",
    "Now, immediately I'd want to band as we assume people of similar ages have similar enough characteristics. Furthermore, from an actuarial/rate perspective we'd do that all the time (for that or whatever other reasns). It definitely makes things simpler. I'm pretty sure even after banding we'd still consider specific ages.\n",
    "\n",
    "So, starting from 18-22, simplifying all that to the '20' band.... and we'd likely either make the 60 band, consisting of people (by default) 58-62 to be bigger and also have 63 and 64... or a smaller 'old' band of anybody beyond that. Initially I was inclined a bigger final one, but my current desire is to have a smaller older band at our conclusion: It's flexible to account for a theortical change of data (that go beyond 64), retains spirit of my old work where we'd have a senior category, and it's funny (I plan on calling it 'oldies' or 'dinosaurs').\n",
    "\n",
    "Anyways, essentially normally distributed around 41. Decent standard deviation, but makes sense given stuff (vague)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4834e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_band_names = []\n",
    "for band in range(20,65, 5):\n",
    "    age_band_names.append(band)\n",
    "# print(names)\n",
    "\n",
    "for feature in age_band_names:\n",
    "    cond1 = feature - 2\n",
    "    cond2 = feature + 2\n",
    "    df[str(feature)] = [1 if (age >= cond1 and age <= cond2) else 0 for age in df['age']]\n",
    "\n",
    "#ChatGPT recommended something like this, but eh...\n",
    "# for band in age_band_names[:-1]:  # Handle all except 'dinosaurs'\n",
    "#     lower, upper = map(int, band.split('-'))\n",
    "#     df[band] = ((df['age'] >= lower - 2) & (df['age'] <= upper + 2)).astype(int)\n",
    "    \n",
    "df['dinosaurs'] = (df['age'] > age_band_names[-1]+2).astype(int)#I'll keep their version. And they were right - why bother\n",
    "#adding it earlier then have to deal with exception stuff if it's really just this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b2e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 2, gender.\n",
      "~~~\n",
      "gender\n",
      "Male      0.502143\n",
      "Female    0.497858\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pd.reset_option('display.float_format')\n",
    "\n",
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "\n",
    "#Nice even split. approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96e45265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = [0 if gender == 'Female' else 1 for gender in df['gender']] #Recall that only a definite female\n",
    "#we defined as male, with that gender abosrbing any 'other' - which would include an unknown. Especially in this data\n",
    "#when it'd be the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e73e020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 3, annual_income.\n",
      "Reminder that annual_income has 44949 nulls (0.037%) - deal with them noob.\n",
      "~~~\n",
      "count   1,155,051.00\n",
      "mean       32,745.22\n",
      "std        32,179.51\n",
      "min             1.00\n",
      "25%         8,001.00\n",
      "50%        23,911.00\n",
      "75%        44,634.00\n",
      "max       149,997.00\n",
      "Name: annual_income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e8a9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yeah, I should really keep the filling a seperate cell. Regardless. Let's analyze:\n",
    "#Unexpectedly skewed to the right, with the median quite lower than the mean... Funny what year the date is based off of\n",
    "#given inflation and the like. Regardless, the trend holds true.\n",
    "\n",
    "#I'd expect a strong correlation to health, as by default if they can't even afford healthcare... At the same time, I recall\n",
    "#the quandry of a certain streamer - if you're broke you get it for free and if you're rich it doesn't matter, but all the\n",
    "#middl class.... And, evn thte upper tiers I could imagine depending upon their scenarios.... Ie even 150k is not all hat\n",
    "#much in 2025....\n",
    "\n",
    "df['annual_income'].fillna(df['annual_income'].median(), inplace=True) #Especially when either way I'd want to copy\n",
    "#the code later on - I might as well get into the habit of using the precise name - as opposed to the variable is. Lest\n",
    "#I mess up, want to change something, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d736bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 4, marital_status.\n",
      "Reminder that marital_status has 18529 nulls (0.015%) - deal with them noob.\n",
      "~~~\n",
      "marital_status\n",
      "Single     0.33\n",
      "Married    0.33\n",
      "Divorced   0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb66045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even enough distribution. Shame with the Pandas rounding as I'm sure it's not precise. Hmm, maybe I should just do both?\n",
    "#So, in this case I'd assume single as definitionally they have themselves, so logically it would be the 'baseline'.\n",
    "\n",
    "df['marital_status'].fillna('Single', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf4b8a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 5, number_of_dependents.\n",
      "Reminder that number_of_dependents has 109672 nulls (0.091%) - deal with them noob.\n",
      "~~~\n",
      "number_of_dependents\n",
      "3.00   0.20\n",
      "4.00   0.20\n",
      "0.00   0.20\n",
      "2.00   0.20\n",
      "1.00   0.20\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a691e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll assume 0. Albeit not the median (2) I'd rather not add something when by default I can't prove its existence.\n",
    "#I don't like this wording, but I'm trying to say: Unlike age where they must be something definitionally, there doesn't\n",
    "#have to be dependents. Hence, without proof or any other additional considerations, I'd assume the default of 0.\n",
    "\n",
    "df['number_of_dependents'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64fc1efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 6, education_level.\n",
      "~~~\n",
      "education_level\n",
      "Master's      0.25\n",
      "PhD           0.25\n",
      "Bachelor's    0.25\n",
      "High School   0.24\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Likely because it's synthetic, but eh - I'm not liking these even splits.... Phds should be much smaller... Oh well.\n",
    "#Reminder to dummify (forgot to do that). Not as relevant anymore as we're dummifying at the end.\n",
    "#Oh, hence, what we discussed earlier: Might be a move to have that list. of objects.. oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b43c72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 7, occupation.\n",
      "Reminder that occupation has 358075 nulls (0.298%) - deal with them noob.\n",
      "~~~\n",
      "occupation\n",
      "Employed        0.34\n",
      "Self-Employed   0.34\n",
      "Unemployed      0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4caf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like number of dependents, I'll assume no job.\n",
    "df['occupation'].fillna('Unemployed', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "005e3590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 8, health_score.\n",
      "Reminder that health_score has 74076 nulls (0.062%) - deal with them noob.\n",
      "~~~\n",
      "count   1,125,924.00\n",
      "mean           25.61\n",
      "std            12.20\n",
      "min             2.01\n",
      "25%            15.92\n",
      "50%            24.58\n",
      "75%            34.53\n",
      "max            58.98\n",
      "Name: health_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "\n",
    "#Tangential, but a bit tempted to try something like this:\n",
    "#I'm getting tired of having to rechange the code dep. on the type of feature.\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec39d3a",
   "metadata": {},
   "source": [
    "Tangential (again) but I wonder if for EDA such as this it might be better to just make an initia split of (suspected) categorical and numeric variables and go down with them. Eh... we'll see.\n",
    "\n",
    "Off hand I don't recall a definition of healthscare. However, the point is clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cb95941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['health_score'].fillna(df['health_score'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03578bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 9, location.\n",
      "~~~\n",
      "location\n",
      "Suburban   0.33\n",
      "Rural      0.33\n",
      "Urban      0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "#Seriously, these splits are waaaay too even. One thing if this would be classification and we're talking about our targt,\n",
    "#but for the features.... and every single one? I supposeit is ideal, but I don't want that in my data!!!\n",
    "\n",
    "#Until data gets interesting I won't bother to comment. Ie even if realistically the groups should be skewed in whatever way,\n",
    "#like expecting a minority of Phds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd2b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 10, policy_type.\n",
      "~~~\n",
      "policy_type\n",
      "Premium         0.33\n",
      "Comprehensive   0.33\n",
      "Basic           0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Would expect and hope premium pays more. Potentialy could make these hierarchical. But, for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3b8702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 11, previous_claims.\n",
      "Reminder that previous_claims has 364029 nulls (0.303%) - deal with them noob.\n",
      "~~~\n",
      "previous_claims\n",
      "0.00   0.37\n",
      "1.00   0.36\n",
      "2.00   0.20\n",
      "3.00   0.06\n",
      "4.00   0.01\n",
      "5.00   0.00\n",
      "6.00   0.00\n",
      "7.00   0.00\n",
      "8.00   0.00\n",
      "9.00   0.00\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8cb2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   835,971.00\n",
      "mean          1.00\n",
      "std           0.98\n",
      "min           0.00\n",
      "25%           0.00\n",
      "50%           1.00\n",
      "75%           2.00\n",
      "max           9.00\n",
      "Name: previous_claims, dtype: float64\n",
      "669462 530538\n"
     ]
    }
   ],
   "source": [
    "#Makes sense to see such a skew, as unlikely for people to have more and more.\n",
    "#Note that the max is actually 9 (well, we know that from our code logic already):\n",
    "print(df['previous_claims'].describe())\n",
    "atleast_1 = sum(df['previous_claims']>0)\n",
    "print(df.shape[0] - atleast_1, atleast_1)\n",
    "\n",
    "#Like before with dependents. See our logic there.\n",
    "df['previous_claims'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670d442",
   "metadata": {},
   "source": [
    "Wow what a mean considering all the 0s. Guess it's not that surprising as the 0s and 1s average out to be .5 then consider all the rest... Regardless, let's see (and comment in this block) if it's at least one:\n",
    "\n",
    "Yeah, then this is quite interesting. Now we see a a hefty skew to the right (before the opposite, albeit not as exagerated). Ie you got those 'unhealthy' people always getting sick. Potentially they didn't get enough care. Regardless, the regulars dominate the activity here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb558ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   530,538.00\n",
       "mean          1.58\n",
       "std           0.78\n",
       "min           1.00\n",
       "25%           1.00\n",
       "50%           1.00\n",
       "75%           2.00\n",
       "max           9.00\n",
       "Name: previous_claims, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['previous_claims']>0]['previous_claims'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ac7e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 12, vehicle_age.\n",
      "Reminder that vehicle_age has 6 nulls (0.0%) - deal with them noob.\n",
      "~~~\n",
      "count   1,199,994.00\n",
      "mean            9.57\n",
      "std             5.78\n",
      "min             0.00\n",
      "25%             5.00\n",
      "50%            10.00\n",
      "75%            15.00\n",
      "max            19.00\n",
      "Name: vehicle_age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "748699b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61615, 0.051)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bit to the lft, but overall nice distribution. Honestly should be expected with this dataset by now...\n",
    "\n",
    "#Of note are these babies - notice how we have only whole numbers so likly they're just very new cars.\n",
    "\n",
    "sum(df['vehicle_age']==0), round(sum(df['vehicle_age']==0)/df.shape[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e9d5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_age'].fillna(df['vehicle_age'].median(), inplace=True) #Like human age must be something. In this case with so\n",
    "#Few nulls though a bit negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96053df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 13, credit_score.\n",
      "Reminder that credit_score has 137882 nulls (0.115%) - deal with them noob.\n",
      "~~~\n",
      "count   1,062,118.00\n",
      "mean          592.92\n",
      "std           149.98\n",
      "min           300.00\n",
      "25%           468.00\n",
      "50%           595.00\n",
      "75%           721.00\n",
      "max           849.00\n",
      "Name: credit_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Again, another clean even (ess.) dist.. Recall that the max is 300 and absolute is 850.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6921efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_score'].fillna(df['credit_score'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4ab9e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Master's      0.26\n",
       "PhD           0.25\n",
       "Bachelor's    0.25\n",
       "High School   0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just for kicks, I want to see how evenly distributed some of the variables are:\n",
    "df[df['credit_score']<350]['education_level'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08361ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "PhD           0.26\n",
       "Bachelor's    0.25\n",
       "Master's      0.25\n",
       "High School   0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['credit_score']>800]['education_level'].value_counts(normalize=True)\n",
    "#Unsurprising...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f6ab979",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We now fixed this, but regardless:\n",
    "\n",
    "# Oh gf me - forgot to dummify this stuff. Given this last bit of code it might be better to dummify at the end.\n",
    "# Or, do something like keeping the original. Do my EDA, then redo the dummification/actually do it at the end.\n",
    "# Especially when either way we'd need to do so for the test data we might as well not get ourselves confused with that (\n",
    "# recall the +1 potential disasters of our i-scrolling) & avoid this issue [easily compare all of a feature's categories\n",
    "# together].\n",
    "\n",
    "# From ChatGPT I'll sort out later.... Enough of the coding and analysis practice for today.\n",
    "\n",
    "# df['occupation_original'] = df['occupation']  # Preserve original column\n",
    "# df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56965bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_col = df['occupation']\n",
    "# df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "# df.insert(0, 'occupation_original', original_col)  # Insert at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb2956da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 14, insurance_duration.\n",
      "Reminder that insurance_duration has 1 nulls (0.0%) - deal with them noob.\n",
      "~~~\n",
      "insurance_duration\n",
      "9.00   0.11\n",
      "1.00   0.11\n",
      "8.00   0.11\n",
      "7.00   0.11\n",
      "5.00   0.11\n",
      "4.00   0.11\n",
      "6.00   0.11\n",
      "3.00   0.11\n",
      "2.00   0.11\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Unsure if this is in months or years. It also just dawned on me - was this for car data? Would makee sense given the vehicle\n",
    "#age feature. Just assumed it was health. Oh well - all the ideas remain the same....\n",
    "\n",
    "#Hmm, I double chcked th page and I'm honestly not convinced from the page. Awkward... Inclined to still assume health/life though.\n",
    "#Now, does it matter? Potentially not. But that's a discussion for later (likely when we get to premium)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cdb6ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   1,199,999.00\n",
       "mean            5.02\n",
       "std             2.59\n",
       "min             1.00\n",
       "25%             3.00\n",
       "50%             5.00\n",
       "75%             7.00\n",
       "max             9.00\n",
       "Name: insurance_duration, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['insurance_duration'].describe() #Ooh quite a nice distribution. Seriously though, these are all way too organized..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61edecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just one null - replacing it with the median which is approx. the mean...\n",
    "df['insurance_duration'].fillna(5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "468d121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 15, policy_start_date.\n",
      "~~~\n",
      "policy_start_date\n",
      "2020-02-08 15:21:39.134960   0.00\n",
      "2023-08-13 15:21:39.155231   0.00\n",
      "2022-02-02 15:21:39.134960   0.00\n",
      "2022-08-30 15:21:39.134960   0.00\n",
      "2023-11-02 15:21:39.134960   0.00\n",
      "                             ... \n",
      "2021-06-07 15:21:39.104139   0.00\n",
      "2024-07-19 15:21:39.233998   0.00\n",
      "2019-12-14 15:21:39.110557   0.00\n",
      "2020-07-23 15:21:39.217387   0.00\n",
      "2020-10-19 15:21:39.118178   0.00\n",
      "Name: proportion, Length: 167381, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Yeah, we gotta clean the times. Or at least do something (potentially ignore...) with them. For now let's do the easy stuff.\n",
    "#To at least analyze: Month might matter. Day of week/weekend might matter. Time might mater..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea041801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 16, customer_feedback.\n",
      "Reminder that customer_feedback has 77824 nulls (0.065%) - deal with them noob.\n",
      "~~~\n",
      "customer_feedback\n",
      "Average   0.34\n",
      "Poor      0.33\n",
      "Good      0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "    \n",
    "#Unlike education level, likely a lot more justified to map these two numbers: -1, 0, 1 seems the most logical to me.\n",
    "#Still might be worthwhile to dummify like the rest; but I won't.\n",
    "#Ie with education I don't think the advantages of increasing the education are linear (rather diminishing returns after\n",
    "#bachelors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95e150e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_feedback'].fillna('Average', inplace=True)\n",
    "#From ChatGPT for convenience:\n",
    "\n",
    "mapping = {\n",
    "    'Poor': -1,\n",
    "    'Average': 0,\n",
    "    'Good': 1\n",
    "}\n",
    "df['customer_feedback'] = df['customer_feedback'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57b86270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_feedback\n",
       " 0   0.38\n",
       "-1   0.31\n",
       " 1   0.31\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customer_feedback'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c874ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 17, smoking_status.\n",
      "~~~\n",
      "smoking_status\n",
      "Yes   0.50\n",
      "No    0.50\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "#Come on - even by the smokers?!?!? Perhaps weed, heh.\n",
    "#Onn the topic that's actualyl quite interesting - smoking what? Historically would be cigarettes, but in 2025 likely th\n",
    "#percenages of 'smokers' and their relativ changes in health vary quite a lot from drug to drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b436503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smoking_status'] = [0 if status == 'No' else 1 for status in df['smoking_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85bd66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 18, exercise_frequency.\n",
      "~~~\n",
      "exercise_frequency\n",
      "Weekly    0.26\n",
      "Monthly   0.25\n",
      "Rarely    0.25\n",
      "Daily     0.25\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cd3c9",
   "metadata": {},
   "source": [
    "Hmm, likely this should be dummified as I venture the health changes are definitely not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d4ca624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 19, property_type.\n",
      "~~~\n",
      "property_type\n",
      "House       0.33\n",
      "Apartment   0.33\n",
      "Condo       0.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))\n",
    "#Perhaps another proxy of stability and healtth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6efba6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 20, premium_amount.\n",
      "~~~\n",
      "count   1,200,000.00\n",
      "mean        1,102.54\n",
      "std           865.00\n",
      "min            20.00\n",
      "25%           514.00\n",
      "50%           872.00\n",
      "75%         1,509.00\n",
      "max         4,999.00\n",
      "Name: premium_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls ({round(nulls/df.shape[0], 3)}%) - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']:\n",
    "    print(df[df.columns[i]].describe())\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a99aaa4",
   "metadata": {},
   "source": [
    "And now our long awaited target - premium.\n",
    "\n",
    "Nice to finally see a non-normal distrubtion. Notice th hefty skew to the right of quite a larger mean than median. Furthermor, look at that standard deviation - almost as large as the median itself! So, unsurprisingly we see a few people paying a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2feb0ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phew, no nulls.\n"
     ]
    }
   ],
   "source": [
    "#Conf. that I got them all.\n",
    "if sum(df.isnull().sum())==0:\n",
    "    print(\"Phew, no nulls.\")\n",
    "else:\n",
    "    print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc2e68",
   "metadata": {},
   "source": [
    "### Re. time:\n",
    "\n",
    "I think I'll just ignore for now; no noob they might be super-charged if they didn't sign up during open enrollment. Don't be lazy and at least prepare the data - you never have to actually use it... Fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1c551e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['policy_start_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96d939d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['policy_start_date'] = pd.to_datetime(df['policy_start_date'])\n",
    "df['policy_start_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d31abeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_start_date\n",
    "df['psd_year'] = df['policy_start_date'].dt.year\n",
    "df['psd_month'] = df['policy_start_date'].dt.month\n",
    "df['psd_day'] = df['policy_start_date'].dt.day\n",
    "#Eh, we'll end it at day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17514d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_start_date</th>\n",
       "      <th>psd_year</th>\n",
       "      <th>psd_month</th>\n",
       "      <th>psd_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           policy_start_date  psd_year  psd_month  psd_day\n",
       "0 2023-12-23 15:21:39.134960      2023         12       23\n",
       "1 2023-06-12 15:21:39.111551      2023          6       12\n",
       "2 2023-09-30 15:21:39.221386      2023          9       30\n",
       "3 2024-06-12 15:21:39.226954      2024          6       12\n",
       "4 2021-12-01 15:21:39.252145      2021         12        1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()[['policy_start_date', 'psd_year', 'psd_month', 'psd_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per customization/feature-engineering we'll also do if it's a weekend or not. We won't bother gettinginto national holidays,\n",
    "#assuming this is in America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15cc4678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_start_date</th>\n",
       "      <th>psd_day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           policy_start_date psd_day_of_week\n",
       "0 2023-12-23 15:21:39.134960        Saturday\n",
       "1 2023-06-12 15:21:39.111551          Monday\n",
       "2 2023-09-30 15:21:39.221386        Saturday\n",
       "3 2024-06-12 15:21:39.226954       Wednesday\n",
       "4 2021-12-01 15:21:39.252145       Wednesday"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['psd_day_of_week'] = df['policy_start_date'].dt.day_name()\n",
    "df.head()[['policy_start_date', 'psd_day_of_week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25aaca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psd_day_of_week\n",
       "Wednesday   0.14\n",
       "Monday      0.14\n",
       "Tuesday     0.14\n",
       "Sunday      0.14\n",
       "Saturday    0.14\n",
       "Thursday    0.14\n",
       "Friday      0.14\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['psd_day_of_week'].value_counts(normalize=True)#Wow, they even got it even here... Note that I definitely doubt this in\n",
    "#real life.... Even more than the phd distribution - aint nobody want to work on the weekend! #Loverboy, heh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a5b064d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psd_year\n",
       "2022   0.20\n",
       "2021   0.20\n",
       "2020   0.20\n",
       "2023   0.20\n",
       "2024   0.12\n",
       "2019   0.07\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['psd_year'].value_counts(normalize=True) #Bit more of a change here. We ake it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e8355fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psd_month\n",
       "5    0.09\n",
       "3    0.09\n",
       "8    0.08\n",
       "4    0.08\n",
       "7    0.08\n",
       "11   0.08\n",
       "10   0.08\n",
       "9    0.08\n",
       "1    0.08\n",
       "6    0.08\n",
       "12   0.08\n",
       "2    0.08\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['psd_month'].value_counts(normalize=True) #Even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e37f1c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psd_day\n",
       "31   0.02\n",
       "30   0.03\n",
       "10   0.03\n",
       "28   0.03\n",
       "29   0.03\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['psd_day'].value_counts(normalize=True).sort_values(ascending=True)[:5] #\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd398268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hmm, so let's dummify the days. I'll leave the f.engineering at if it's a weekend though.\n",
    "weekend = ['Saturday', 'Sunday']\n",
    "df['psd_weekend'] = [1 if day in weekend else 0 for day in df['psd_day_of_week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy section, as we want to keep th categories as strings/objects at the moment for easier eda\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['marital_status'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['education_level'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['location'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['policy_type'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['exercise_frequency'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['property_type'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['psd_day_of_week'], dtype=int, drop_first=True) #Hmm, in this case a bit more inclined to actually\n",
    "#not drop the first. Perhaps because intuitivlely day_x is easier to compare than say education_x vs. anything else.\n",
    "##ManicMondays #HavingFunWithMyReferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd311c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>education_level</th>\n",
       "      <th>occupation</th>\n",
       "      <th>health_score</th>\n",
       "      <th>location</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>previous_claims</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>insurance_duration</th>\n",
       "      <th>policy_start_date</th>\n",
       "      <th>customer_feedback</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>exercise_frequency</th>\n",
       "      <th>property_type</th>\n",
       "      <th>premium_amount</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "      <th>55</th>\n",
       "      <th>60</th>\n",
       "      <th>dinosaurs</th>\n",
       "      <th>psd_year</th>\n",
       "      <th>psd_month</th>\n",
       "      <th>psd_day</th>\n",
       "      <th>psd_day_of_week</th>\n",
       "      <th>psd_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10,049.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.60</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>2.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2,869.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0</td>\n",
       "      <td>31,678.00</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>15.57</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>694.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "      <td>1,483.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1</td>\n",
       "      <td>25,602.00</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.00</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>47.18</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>595.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>567.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1</td>\n",
       "      <td>141,855.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>10.94</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>367.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>765.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1</td>\n",
       "      <td>39,651.00</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.38</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Premium</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>598.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2,022.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  gender  annual_income marital_status  number_of_dependents  \\\n",
       "0   0 19.00       0      10,049.00        Married                  1.00   \n",
       "1   1 39.00       0      31,678.00       Divorced                  3.00   \n",
       "2   2 23.00       1      25,602.00       Divorced                  3.00   \n",
       "3   3 21.00       1     141,855.00        Married                  2.00   \n",
       "4   4 21.00       1      39,651.00         Single                  1.00   \n",
       "\n",
       "  education_level     occupation  health_score  location    policy_type  \\\n",
       "0      Bachelor's  Self-Employed         22.60     Urban        Premium   \n",
       "1        Master's     Unemployed         15.57     Rural  Comprehensive   \n",
       "2     High School  Self-Employed         47.18  Suburban        Premium   \n",
       "3      Bachelor's     Unemployed         10.94     Rural          Basic   \n",
       "4      Bachelor's  Self-Employed         20.38     Rural        Premium   \n",
       "\n",
       "   previous_claims  vehicle_age  credit_score  insurance_duration  \\\n",
       "0             2.00        17.00        372.00                5.00   \n",
       "1             1.00        12.00        694.00                2.00   \n",
       "2             1.00        14.00        595.00                3.00   \n",
       "3             1.00         0.00        367.00                1.00   \n",
       "4             0.00         8.00        598.00                4.00   \n",
       "\n",
       "           policy_start_date  customer_feedback  smoking_status  \\\n",
       "0 2023-12-23 15:21:39.134960                 -1               0   \n",
       "1 2023-06-12 15:21:39.111551                  0               1   \n",
       "2 2023-09-30 15:21:39.221386                  1               1   \n",
       "3 2024-06-12 15:21:39.226954                 -1               1   \n",
       "4 2021-12-01 15:21:39.252145                 -1               1   \n",
       "\n",
       "  exercise_frequency property_type  premium_amount  20  25  30  35  40  45  \\\n",
       "0             Weekly         House        2,869.00   1   0   0   0   0   0   \n",
       "1            Monthly         House        1,483.00   0   0   0   0   1   0   \n",
       "2             Weekly         House          567.00   0   1   0   0   0   0   \n",
       "3              Daily     Apartment          765.00   1   0   0   0   0   0   \n",
       "4             Weekly         House        2,022.00   1   0   0   0   0   0   \n",
       "\n",
       "   50  55  60  dinosaurs  psd_year  psd_month  psd_day psd_day_of_week  \\\n",
       "0   0   0   0          0      2023         12       23        Saturday   \n",
       "1   0   0   0          0      2023          6       12          Monday   \n",
       "2   0   0   0          0      2023          9       30        Saturday   \n",
       "3   0   0   0          0      2024          6       12       Wednesday   \n",
       "4   0   0   0          0      2021         12        1       Wednesday   \n",
       "\n",
       "   psd_weekend  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head() #Hmm, is it a move to rearrange the target to the end? Oh well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be235f",
   "metadata": {},
   "source": [
    "## Concluding Matters\n",
    "\n",
    "Hmm, from an efficiency standpoint I wonder if it's better to not even change the original data and just post here, even for the train data, all the various changes - just once.\n",
    "\n",
    "Yeah, as I decided earlier, we'll try to keep analysis separate next time and just have all the various changes we do to\n",
    "clean the data at the end. At least for now (2/13/25) I'll be leaving the code as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a627d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phew, no nulls.\n",
      "(1200000, 50)\n"
     ]
    }
   ],
   "source": [
    "# #As I said earlier, prepping the total changed cleanings for modeling.\n",
    "# #Ie kind of like on Git we have the commit before actually pushing.\n",
    "# df = pd.read_csv('../data/train.csv')\n",
    "# df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '')\n",
    "# for col in df.columns:\n",
    "#     try:\n",
    "#         df[col] = round(df[col], 3)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "# age_band_names = []\n",
    "# for band in range(20,65, 5):\n",
    "#     age_band_names.append(band)\n",
    "# for feature in age_band_names:\n",
    "#     cond1 = feature - 2\n",
    "#     cond2 = feature + 2\n",
    "#     df[str(feature)] = [1 if (age >= cond1 and age <= cond2) else 0 for age in df['age']]\n",
    "# df['dinosaurs'] = (df['age'] > age_band_names[-1]+2).astype(int)\n",
    "\n",
    "# df['gender'] = [0 if gender == 'Female' else 1 for gender in df['gender']]\n",
    "\n",
    "# df['annual_income'].fillna(df['annual_income'].median(), inplace=True)\n",
    "\n",
    "# df['marital_status'].fillna('Single', inplace=True)\n",
    "\n",
    "# df['number_of_dependents'].fillna(0, inplace=True)\n",
    "\n",
    "# df['occupation'].fillna('Unemployed', inplace=True)\n",
    "\n",
    "# df['health_score'].fillna(df['health_score'].median(), inplace=True)\n",
    "\n",
    "# df['previous_claims'].fillna(0, inplace=True)\n",
    "\n",
    "# df['vehicle_age'].fillna(df['vehicle_age'].median(), inplace=True)\n",
    "\n",
    "# df['credit_score'].fillna(df['credit_score'].median(), inplace=True)\n",
    "\n",
    "# df['insurance_duration'].fillna(5, inplace=True)\n",
    "\n",
    "# df['customer_feedback'].fillna('Average', inplace=True)\n",
    "# mapping = {\n",
    "#     'Poor': -1,\n",
    "#     'Average': 0,\n",
    "#     'Good': 1\n",
    "# }\n",
    "# df['customer_feedback'] = df['customer_feedback'].map(mapping)\n",
    "\n",
    "# df['smoking_status'] = [0 if status == 'No' else 1 for status in df['smoking_status']]\n",
    "\n",
    "# df['policy_start_date'] = pd.to_datetime(df['policy_start_date'])\n",
    "# df['psd_year'] = df['policy_start_date'].dt.year\n",
    "# df['psd_month'] = df['policy_start_date'].dt.month\n",
    "# df['psd_day'] = df['policy_start_date'].dt.day\n",
    "# df['psd_day_of_week'] = df['policy_start_date'].dt.day_name()\n",
    "# weekend = ['Saturday', 'Sunday']\n",
    "# df['psd_weekend'] = [1 if day in weekend else 0 for day in df['psd_day_of_week']]\n",
    "\n",
    "# if sum(df.isnull().sum())==0:\n",
    "#     print(\"Phew, no nulls.\")\n",
    "# else:\n",
    "#     print(df.columns[df.isnull().any()])\n",
    "\n",
    "# #Dummies now:\n",
    "# df = pd.get_dummies(df, columns=['marital_status'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['education_level'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['location'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['policy_type'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['exercise_frequency'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['property_type'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['psd_day_of_week'], dtype=int, drop_first=True)\n",
    "\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f4847b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48970b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phew, no nulls.\n",
      "(800000, 49)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('../data/test.csv')\n",
    "# df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '')\n",
    "# for col in df.columns:\n",
    "#     try:\n",
    "#         df[col] = round(df[col], 3)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "# age_band_names = []\n",
    "# for band in range(20,65, 5):\n",
    "#     age_band_names.append(band)\n",
    "# for feature in age_band_names:\n",
    "#     cond1 = feature - 2\n",
    "#     cond2 = feature + 2\n",
    "#     df[str(feature)] = [1 if (age >= cond1 and age <= cond2) else 0 for age in df['age']]\n",
    "# df['dinosaurs'] = (df['age'] > age_band_names[-1]+2).astype(int)\n",
    "\n",
    "# df['gender'] = [0 if gender == 'Female' else 1 for gender in df['gender']]\n",
    "\n",
    "# df['annual_income'].fillna(df['annual_income'].median(), inplace=True)\n",
    "\n",
    "# df['marital_status'].fillna('Single', inplace=True)\n",
    "\n",
    "# df['number_of_dependents'].fillna(0, inplace=True)\n",
    "\n",
    "# df['occupation'].fillna('Unemployed', inplace=True)\n",
    "\n",
    "# df['health_score'].fillna(df['health_score'].median(), inplace=True)\n",
    "\n",
    "# df['previous_claims'].fillna(0, inplace=True)\n",
    "\n",
    "# df['vehicle_age'].fillna(df['vehicle_age'].median(), inplace=True)\n",
    "\n",
    "# df['credit_score'].fillna(df['credit_score'].median(), inplace=True)\n",
    "\n",
    "# df['insurance_duration'].fillna(5, inplace=True)\n",
    "\n",
    "# df['customer_feedback'].fillna('Average', inplace=True)\n",
    "# mapping = {\n",
    "#     'Poor': -1,\n",
    "#     'Average': 0,\n",
    "#     'Good': 1\n",
    "# }\n",
    "# df['customer_feedback'] = df['customer_feedback'].map(mapping)\n",
    "\n",
    "# df['smoking_status'] = [0 if status == 'No' else 1 for status in df['smoking_status']]\n",
    "\n",
    "# df['policy_start_date'] = pd.to_datetime(df['policy_start_date'])\n",
    "# df['psd_year'] = df['policy_start_date'].dt.year\n",
    "# df['psd_month'] = df['policy_start_date'].dt.month\n",
    "# df['psd_day'] = df['policy_start_date'].dt.day\n",
    "# df['psd_day_of_week'] = df['policy_start_date'].dt.day_name()\n",
    "# weekend = ['Saturday', 'Sunday']\n",
    "# df['psd_weekend'] = [1 if day in weekend else 0 for day in df['psd_day_of_week']]\n",
    "\n",
    "# if sum(df.isnull().sum())==0:\n",
    "#     print(\"Phew, no nulls.\")\n",
    "# else:\n",
    "#     print(df.columns[df.isnull().any()])\n",
    "\n",
    "# #Dummies now:\n",
    "# df = pd.get_dummies(df, columns=['marital_status'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['education_level'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['occupation'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['location'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['policy_type'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['exercise_frequency'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['property_type'], dtype=int, drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['psd_day_of_week'], dtype=int, drop_first=True)\n",
    "\n",
    "# print(df.shape) #I'm curious. Pre-gaming the train. By the way - we did all our eda on just the train - AND NOT the test.\n",
    "# #So, obviously I am assuming that the data is comprababl. And, I hope hta is reasonable... Eh, let us continue.\n",
    "\n",
    "# #Honestly, if this would be a formal business problem I would check. Perhaps could write some code to do so. Ie if the means of the\n",
    "# #various features are  close enough..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b8c14d",
   "metadata": {},
   "source": [
    "## Hold Up\n",
    "\n",
    "Wait, we have 49 features there?? OH yeah - recall our last shape as before that. From quick math: It probably adds up. Well, guess we'll see later.\n",
    "\n",
    "Eh don't be lazy and re run it - Hmmmmmm 50 vs. 49.... Oh yeah - no premium! Mmk so we're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20107017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/cleaned_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
